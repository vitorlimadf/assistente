# Assistente Pessoal com Ollama, OpenRouter, LangGraph e Streamlit

Este projeto implementa um assistente pessoal de linguagem natural que roda localmente, combinando:

- [LangGraph](https://github.com/langchain-ai/langgraph) para orquestra√ß√£o de agentes
- [LangChain](https://github.com/langchain-ai/langchain) para ferramentas, mem√≥ria e integra√ß√£o
- [Ollama](https://ollama.com) para execu√ß√£o local de modelos de linguagem (LLMs)
- [Streamlit](https://streamlit.io/) para interface web simples e leve
- [OpenRouter](https://openrouter.ai/) adicionado posteriormente para casos de limita√ß√£o de hardware

---

## Requisitos

- Python 3.10 ou superior  
- [Ollama](https://ollama.com/download) instalado  
- Git instalado  

---

## Instala√ß√£o

### 1. Clone este reposit√≥rio

```bash
git clone https://github.com/vitorlimadf/assistente.git
cd assistente
```

### 2. Crie e ative um ambiente virtual

```bash
python -m venv .venv
source .venv/bin/activate  # Linux/macOS
.venv\Scripts\activate     # Windows
```

### 3. Instale as depend√™ncias

```bash
pip install -r requirements.txt
```

---

## Baixando o Modelo

Antes de executar o assistente, baixe um modelo local com Ollama:

```bash
ollama pull mistral
```

Outros modelos compat√≠veis (falta testar todos):

- `llama3`
- `openchat`
- `gemma`
- `nous-hermes2`

Voc√™ pode alternar o modelo utilizado alterando o nome no c√≥digo ou utilizando uma vari√°vel de ambiente (`LLM_MODEL`).

---

## Executando o Assistente

### 1. (Opcional) Inicie manualmente o servidor do Ollama

```bash
ollama serve
```

Na maioria dos casos, isso ocorre automaticamente em segundo plano.

### 2. Execute a interface web

```bash
streamlit run app.py
```

Acesse via navegador em [http://localhost:8501](http://localhost:8501)

---

## Estrutura do Projeto

```
üìÅ seu-repositorio/
‚îú‚îÄ‚îÄ app_graph.py         # Interface web com Streamlit
‚îú‚îÄ‚îÄ agente_graph.py      # L√≥gica do agente com LangGraph + Ollama + OpenRouter
‚îú‚îÄ‚îÄ token_manager        # gerenciamento de tokens de acesso para conectar ao e-mail
‚îú‚îÄ‚îÄ requirements.txt     # Depend√™ncias do projeto
‚îî‚îÄ‚îÄ README.md            # Este arquivo
```

---

## Observa√ß√µes T√©cnicas

A classe `ChatOllama` foi migrada para o pacote `langchain-ollama`. Para evitar avisos de deprecia√ß√£o:

```bash
pip install -U langchain-ollama
```

E utilize:

```python
from langchain_ollama import ChatOllama
```

---


TODO: Atualizar com informa√ß√µes de como conectar ao e-mail

## Executando os Testes

Para garantir que tudo est√° funcionando corretamente, rode a su√≠te de testes:

```bash
pip install pytest
pytest
```

## Licen√ßa

Este projeto √© open-source e pode ser utilizado, modificado e redistribu√≠do livremente, conforme os termos da licen√ßa inclu√≠da no reposit√≥rio.

Desenvolvido por Vitor Lima (E pelo ChatGPT, √© claro :)
